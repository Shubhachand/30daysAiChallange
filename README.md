Welcome to my journey through the **30 Days of AI Voice Agents** challenge! üöÄ  
This repo tracks my progress from **Day 1 to Day 30**, building AI-powered voice apps using **FastAPI**, **AssemblyAI**, and other tools. Each day, we build something new ‚Äì from simple TTS to real-time transcription bots.

---

## üìÖ Progress Overview

| Day | Task Description                             | Status  |
|-----|----------------------------------------------|---------|
| ‚úÖ 1 | Setup FastAPI server & UI                    | ‚úÖ Done |
| ‚úÖ 2 | Integrated Text-to-Speech (TTS) using Murf   | ‚úÖ Done |
| ‚úÖ 3 | UI for Echo Bot with recording               | ‚úÖ Done |
| ‚úÖ 4 | Visualize live audio waveform                | ‚úÖ Done |
| ‚úÖ 5 | Upload audio to server via endpoint          | ‚úÖ Done |
| ‚úÖ 6 | Transcribe audio using AssemblyAI            | ‚úÖ Done |
| ‚úÖ 7 | Echo Bot v2 ‚Äì Record ‚Üí Transcribe ‚Üí AI Voice | ‚úÖ Done |
| ‚úÖ 9 | Full non-streaming AI conversation pipeline  | ‚úÖ Done |
| ‚úÖ 10| Automatic continuous conversations           | ‚úÖ Done |
| ‚úÖ 11| Error handling & graceful recovery           | ‚úÖ Done |
| ‚úÖ 12| UI revamp & conversation flow upgrade        | ‚úÖ Done |
| ‚è≥ 13‚Äì29 | Coming soon...                           | Ongoing |
| üîú 30 | Final App + LinkedIn Post + Deployment üéâ   | Pending |

---

## üî• What We Built So Far

### ‚úÖ Day 1 ‚Äì Project Setup & UI Bootstrapping
- Initialized FastAPI backend
- Created clean responsive UI using HTML & CSS
- Setup file structure: `static/`, `templates/`, `main.py`

---

### ‚úÖ Day 2 ‚Äì Text-to-Speech with Murf.ai
- Connected Murf API to backend
- Built `/generate` endpoint
- User enters text ‚Üí Audio is generated
- Audio is playable from the UI

---

### ‚úÖ Day 3 ‚Äì Echo Bot Recording UI
- Added recording functionality using `MediaRecorder` API
- Start/Stop buttons to control audio recording
- Saved audio locally in memory (no server upload yet)

---

### ‚úÖ Day 4 ‚Äì Audio Waveform Visualizer
- Used `Canvas` to show live audio waveform
- Integrated `AnalyserNode` from Web Audio API
- Made UI futuristic with pulse animations üéß

---

### ‚úÖ Day 5 ‚Äì Upload Audio to Server
- Built `/upload-audio` POST endpoint
- Saved uploaded audio file in `/uploads` directory
- Returned file name, type, and size from server
- Displayed upload status in frontend

---

### ‚úÖ Day 6 ‚Äì Transcribe Audio via AssemblyAI
- Used AssemblyAI Python SDK
- Created `/transcribe/file` endpoint that:
  - Accepts audio file
  - Transcribes using `transcribe(audio_data)`
  - Returns full transcript
- Displayed transcription on frontend after recording

---
### ‚úÖ  Day 7 ‚Äì Echo Bot v2 üé§‚ú®

- Record audio in the browser
- Upload to backend via /tts/echo endpoint
 - Transcribe audio using AssemblyAI
 - Generate AI voice from transcription using Murf API
 - Play back the AI-generated voice in the browser
 - It‚Äôs like talking to yourself‚Ä¶ but in a perfect studio voice üéôÔ∏è
---
### ‚úÖ Day 8 ‚Äì LLM Integration with Google Gemini ü§ñ
- Added `/llm/query` endpoint in FastAPI backend  
- Connected to Google‚Äôs Gemini API for intelligent, context-aware replies  
- Successfully tested ‚Äî the LLM can explain Murf AI features üìù‚ú®  
- Prepares the bot for natural, conversational responses  

---

### ‚úÖ Day 9 ‚Äì Full Non-Streaming AI Conversation Pipeline üéØ
- Implemented **listen ‚Üí think ‚Üí talk back** loop:  
  1. üé§ Record voice in browser  
  2. ‚úçÔ∏è Transcribe via AssemblyAI  
  3. üí° Generate smart response via Gemini API  
  4. üé∂ Convert to natural speech using Murf AI  
  5. üîÅ Play AI‚Äôs voice back instantly  
- Now holds voice-only conversations without typing  

---

### ‚úÖ Day 10 ‚Äì Automatic Continuous Conversations üîÑ
- Bot now **listens, thinks, and responds** without extra clicks  
- After speaking, it starts listening again  
- Smooth, delay-free, back-and-forth interaction

---

### ‚úÖ Day 11 ‚Äì Error Handling & Graceful Recovery üí™
- Handled API timeouts, connection drops, and unexpected failures  
- Bot **recovers gracefully** without freezing  
- Friendly fallback messages when something goes wrong

---

### ‚úÖ Day 12 ‚Äì UI Revamp & Conversation Flow Upgrade üé®
- Removed old TTS/Echo Bot UI ‚Üí Now **pure Conversational Agent mode** üéØ  
- Single smart **Start/Stop** button üé§‚èπÔ∏è  
- Added **End Session** button üõë  
- Clean, glowing mic button & sleeker audio visualizer  
- Instant audio playback without bulky players  
- Mobile-friendly redesign üì±  

---


## üõ† Tech Stack

- **Frontend**: HTML5, CSS3, JavaScript (vanilla)
- **Backend**: Python, FastAPI
- **APIs**: Murf.ai (TTS), AssemblyAI (Transcription)
- **Audio**: MediaRecorder API, Web Audio API, Canvas
- **Dev Tools**: VS Code, Postman, Git

---

## ‚öôÔ∏è How to Run Locally

### üöÄ Step-by-Step Guide for Beginners

#### 1Ô∏è‚É£ Clone the Repository
```bash
git clone https://github.com/your-username/ai-voice-agent.git
cd ai-voice-agent
```

#### 2Ô∏è‚É£ Create Virtual Environment
**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Mac/Linux:**
```bash
python3 -m venv venv
source venv/bin/activate
```

> üí° **Tip:** You'll see `(venv)` in your terminal when the virtual environment is active!

#### 3Ô∏è‚É£ Install Dependencies
```bash
pip install -r requirements.txt
```

#### 4Ô∏è‚É£ Set Up Environment Variables
Create a `.env` file in the root directory:
```bash
# Windows
echo. > .env

# Mac/Linux
touch .env
```

Add your API keys to the `.env` file:
```env
MURF_API_KEY=your_murf_api_key_here
ASSEMBLYAI_API_KEY=your_assemblyai_api_key_here
GEMINI_API_KEY=your_gemini_api_key_here
```

> üîë **Where to get API keys:**
> - **Murf.ai**: Sign up at [murf.ai](https://murf.ai)
> - **AssemblyAI**: Create account at [assemblyai.com](https://www.assemblyai.com)
> - **Google Gemini**: Get key from [Google AI Studio](https://makersuite.google.com/app/apikey)

#### 5Ô∏è‚É£ Start the FastAPI Server
```bash
uvicorn main:app --reload
```

> ‚úÖ **Success!** You should see: `Uvicorn running on http://127.0.0.1:8000`

#### 6Ô∏è‚É£ Open in Browser
Navigate to: [http://127.0.0.1:8000](http://127.0.0.1:8000)

---

### üõ†Ô∏è Troubleshooting Tips

**If you get "pip not found":**
- Windows: `python -m pip install --upgrade pip`
- Mac/Linux: `python3 -m pip install --upgrade pip`

**If port 8000 is busy:**
```bash
uvicorn app.main:app --reload --port 8001

```

**To deactivate virtual environment:**
```bash
deactivate
```

### üì± Quick Start Commands (Copy & Paste)
```bash
# All-in-one commands for Windows
git clone https://github.com/your-username/ai-voice-agent.git && cd ai-voice-agent && python -m venv venv && venv\Scripts\activate && pip install -r requirements.txt

# All-in-one commands for Mac/Linux
git clone https://github.com/your-username/ai-voice-agent.git && cd ai-voice-agent && python3 -m venv venv && source venv/bin/activate && pip install -r requirements.txt
```





---

## üöÄ Final Goal (Day 30)

- üéØ Build a **complete AI Voice Agent app**
- üß† Features: TTS + Echo + Transcription + Real-time streaming
- üåê Deploy app on Render / Vercel
- üì∏ Post final demo on [LinkedIn](https://www.linkedin.com/in/shubhachand/)

---


## üì¢ Stay Tuned

> More updates daily...  
Follow along as I turn this into a fully functional **Voice Assistant App**!  
Made with ‚ù§Ô∏è and curiosity.

---

### üë®‚Äçüíª Author

**Shubhachand Patel**  
üßë‚Äçüéì 3rd year student | Full-stack & AI enthusiast  
üîó [LinkedIn](https://www.linkedin.com/in/shubhachand/) 

---

)

---

## üì¢ Stay Tuned

> More updates daily...  
Follow along as I turn this into a fully functional **Voice Assistant App**!  
Made with ‚ù§Ô∏è and curiosity.

---

